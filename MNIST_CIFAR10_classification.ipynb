{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV4mDyqtsjO/66SSYz0qBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DayenaJeong/FS_neuron/blob/main/MNIST_CIFAR10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xEu_GNmJ3gBj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST 다운로드"
      ],
      "metadata": {
        "id": "ZUmVdeQb6HH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터셋의 변환 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # MNIST는 흑백 이미지이므로 채널이 하나\n",
        "])\n",
        "\n",
        "# 훈련 및 테스트 데이터셋 로딩\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 데이터 로더 설정\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw3zz8Qi5288",
        "outputId": "e6f2b7bd-d536-43ad-d635-34aeb97797e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 16374211.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 540434.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4520355.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4751940.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 다운로드"
      ],
      "metadata": {
        "id": "R0T6o8CI6JVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 데이터셋의 변환 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 훈련 및 테스트 데이터셋 로딩\n",
        "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 클래스 필터링: 'airplane', 'automobile', 'bird'는 각각 0, 1, 2 인덱스\n",
        "classes = [0, 1, 2]\n",
        "train_indices = [i for i, (img, label) in enumerate(train_data) if label in classes]\n",
        "test_indices = [i for i, (img, label) in enumerate(test_data) if label in classes]\n",
        "\n",
        "# 데이터셋 필터링\n",
        "filtered_train_data = Subset(train_data, train_indices)\n",
        "filtered_test_data = Subset(test_data, test_indices)\n",
        "\n",
        "# 데이터 로더 설정\n",
        "train_loader = DataLoader(filtered_train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(filtered_test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHAl9Zsx3kSc",
        "outputId": "240a7e59-58ea-4861-dc9a-0be8c301c598"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43009457.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST 분류"
      ],
      "metadata": {
        "id": "vkma82R26Ut_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "간단한 MLP"
      ],
      "metadata": {
        "id": "ztTapZ5HHhWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Swish(nn.Module):\n",
        "    def __init__(self, beta=1.0):\n",
        "        super(Swish, self).__init__()\n",
        "        self.beta = beta  # β is a learnable parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(self.beta * x)"
      ],
      "metadata": {
        "id": "KrFhZMOHtPtx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 신경망 정의\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)  # MNIST 이미지는 28x28 크기\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)  # MNIST에는 10개의 클래스\n",
        "        self.swish = Swish()  # Swish 활성화 함수 인스턴스화\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # 평탄화\n",
        "        x = self.swish(self.fc1(x))\n",
        "        x = self.swish(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# 모델 훈련 및 평가 함수\n",
        "def train_and_evaluate(model, criterion, optimizer, train_loader, test_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                test_acc += accuracy(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_acc /= len(test_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Test Loss: {test_loss}, Test Accuracy: {test_acc}%')\n",
        "\n",
        "# 모델 훈련 및 평가\n",
        "train_and_evaluate(model, criterion, optimizer, train_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfewaa-K6EUu",
        "outputId": "5895b796-2785-46e5-a2af-e9c7be258587"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2727195942488465, Test Loss: 0.13633221003840898, Test Accuracy: 95.53144904458598%\n",
            "Epoch 2, Loss: 0.11955884799484347, Test Loss: 0.10830800770930234, Test Accuracy: 96.6062898089172%\n",
            "Epoch 3, Loss: 0.09106782336792807, Test Loss: 0.0895881741050005, Test Accuracy: 97.29299363057325%\n",
            "Epoch 4, Loss: 0.07376280576358044, Test Loss: 0.09580431943355205, Test Accuracy: 97.07404458598727%\n",
            "Epoch 5, Loss: 0.062447778848823965, Test Loss: 0.09465180829524769, Test Accuracy: 97.15366242038216%\n",
            "Epoch 6, Loss: 0.054923507267609736, Test Loss: 0.07566458663653292, Test Accuracy: 97.9000796178344%\n",
            "Epoch 7, Loss: 0.047483977689623716, Test Loss: 0.11004975775296053, Test Accuracy: 97.04418789808918%\n",
            "Epoch 8, Loss: 0.042082396991604785, Test Loss: 0.0707861085081572, Test Accuracy: 98.06926751592357%\n",
            "Epoch 9, Loss: 0.037818536453119944, Test Loss: 0.0863741654705736, Test Accuracy: 97.61146496815287%\n",
            "Epoch 10, Loss: 0.03409840310567559, Test Loss: 0.08198519209718663, Test Accuracy: 97.8702229299363%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FS Swish"
      ],
      "metadata": {
        "id": "sl7yrn1KHb2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of spike function for PyTorch custom gradient\n",
        "class SpikeFunction(autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, v_scaled):\n",
        "        z_ = torch.where(v_scaled > 0, torch.ones_like(v_scaled), torch.zeros_like(v_scaled))\n",
        "        ctx.save_for_backward(v_scaled)\n",
        "        return z_\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        v_scaled, = ctx.saved_tensors\n",
        "        dz_dv_scaled = torch.maximum(1 - torch.abs(v_scaled), torch.tensor(0.0, device=v_scaled.device))\n",
        "        dE_dv_scaled = grad_output * dz_dv_scaled\n",
        "        return dE_dv_scaled\n",
        "\n",
        "# Call spike function for PyTorch\n",
        "def spike_function(v_scaled):\n",
        "    return SpikeFunction.apply(v_scaled)"
      ],
      "metadata": {
        "id": "UigPuCNOnVmP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=4로 했을 때"
      ],
      "metadata": {
        "id": "7RsZ9uJBob9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FSSwish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FSSwish, self).__init__()\n",
        "        self.h = torch.tensor([5.9128, 2.9864, 1.4755, 0.4429], dtype=torch.float32)\n",
        "        self.d = torch.tensor([6.0788, 3.0843, 1.5167, 0.7723], dtype=torch.float32)\n",
        "        self.T = torch.tensor([5.7271, 2.8642, 1.3162, 0.6181], dtype=torch.float32)\n",
        "        self.K = len(self.h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        v = x\n",
        "\n",
        "        # Initialize temporary output for FS spike neural network\n",
        "        temp_out = torch.zeros_like(v)\n",
        "\n",
        "        # Implement FS spike neural network\n",
        "        for t in range(len(self.T)):\n",
        "            v_scaled = (v - self.T[t]) / (torch.abs(v) + 1)\n",
        "            z = spike_function(v_scaled)\n",
        "            temp_out += z * self.d[t]\n",
        "            v = v - z * self.h[t]\n",
        "\n",
        "        return temp_out"
      ],
      "metadata": {
        "id": "54wUHLsslZaw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.fs_swish1 = FSSwish()\n",
        "        self.fs_swish2 = FSSwish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.fs_swish1(self.fc1(x))\n",
        "        x = self.fs_swish2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 데이터 로딩 및 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# 모델 훈련 및 평가 함수\n",
        "def train_and_evaluate(model, criterion, optimizer, train_loader, test_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                test_acc += accuracy(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_acc /= len(test_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Test Loss: {test_loss}, Test Accuracy: {test_acc}%')\n",
        "\n",
        "# 모델 훈련 및 평가\n",
        "train_and_evaluate(model, criterion, optimizer, train_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZiKXHGI7rnG",
        "outputId": "bd7665db-c609-4d08-af51-f4683f8744bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.29050124780153797, Test Loss: 0.1319344721713762, Test Accuracy: 95.72054140127389%\n",
            "Epoch 2, Loss: 0.13319084876334109, Test Loss: 0.09869940609783884, Test Accuracy: 96.77547770700637%\n",
            "Epoch 3, Loss: 0.09770265747177433, Test Loss: 0.09757748859208581, Test Accuracy: 97.15366242038216%\n",
            "Epoch 4, Loss: 0.08069958772807162, Test Loss: 0.11313831546741678, Test Accuracy: 96.55652866242038%\n",
            "Epoch 5, Loss: 0.06902846806312302, Test Loss: 0.07179615582206181, Test Accuracy: 97.70103503184713%\n",
            "Epoch 6, Loss: 0.058739957208660785, Test Loss: 0.08771366003396917, Test Accuracy: 97.53184713375796%\n",
            "Epoch 7, Loss: 0.051852413685340784, Test Loss: 0.10501125653096027, Test Accuracy: 96.94466560509554%\n",
            "Epoch 8, Loss: 0.04646297352019149, Test Loss: 0.0982094240055277, Test Accuracy: 97.20342356687898%\n",
            "Epoch 9, Loss: 0.04094309258999041, Test Loss: 0.08422336409036753, Test Accuracy: 97.57165605095541%\n",
            "Epoch 10, Loss: 0.035407797746131446, Test Loss: 0.08500293303375796, Test Accuracy: 97.7607484076433%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=16로 했을 때"
      ],
      "metadata": {
        "id": "SGjO4PxyohID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FSSwish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FSSwish, self).__init__()\n",
        "        self.h = torch.tensor([-0.3462,  1.7540,  0.7608,  2.2101,  2.2010,  2.0671,  1.5055,  0.9358,\n",
        "0.7226,  0.5611,  0.4563,  0.3873,  0.3402,  0.3063,  0.2518,  0.2383], dtype=torch.float32)\n",
        "        self.d = torch.tensor([-0.1988,  1.8982,  0.5589,  2.2857,  2.2202,  2.0731,  1.5142,  0.9145,\n",
        "0.6390,  0.4360,  0.3265,  0.2403,  0.1830,  0.1436,  0.1209,  0.1377], dtype=torch.float32)\n",
        "        self.T = torch.tensor([-3.7520,  3.2999,  0.7893,  2.3260,  2.3061,  2.1326,  1.5841,  0.9676,\n",
        "0.7256,  0.5612,  0.4561,  0.3868,  0.3397,  0.3061,  0.2929,  0.2950], dtype=torch.float32)\n",
        "        self.K = len(self.h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        v = x\n",
        "\n",
        "        # Initialize temporary output for FS spike neural network\n",
        "        temp_out = torch.zeros_like(v)\n",
        "\n",
        "        # Implement FS spike neural network\n",
        "        for t in range(len(self.T)):\n",
        "            v_scaled = (v - self.T[t]) / (torch.abs(v) + 1)\n",
        "            z = spike_function(v_scaled)\n",
        "            temp_out += z * self.d[t]\n",
        "            v = v - z * self.h[t]\n",
        "\n",
        "        return temp_out"
      ],
      "metadata": {
        "id": "nb9nfBB9okSv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.fs_swish1 = FSSwish()\n",
        "        self.fs_swish2 = FSSwish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.fs_swish1(self.fc1(x))\n",
        "        x = self.fs_swish2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 데이터 로딩 및 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# 모델 훈련 및 평가 함수\n",
        "def train_and_evaluate(model, criterion, optimizer, train_loader, test_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                test_acc += accuracy(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_acc /= len(test_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Test Loss: {test_loss}, Test Accuracy: {test_acc}%')\n",
        "\n",
        "# 모델 훈련 및 평가\n",
        "train_and_evaluate(model, criterion, optimizer, train_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiQ-TCMHqKHl",
        "outputId": "99bb26b1-638f-433c-8970-9d70b50d677b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2753205719564769, Test Loss: 0.14593418538985645, Test Accuracy: 95.49164012738854%\n",
            "Epoch 2, Loss: 0.12237779358560756, Test Loss: 0.13645759765740934, Test Accuracy: 95.80015923566879%\n",
            "Epoch 3, Loss: 0.09215622913610659, Test Loss: 0.09098237098133856, Test Accuracy: 97.19347133757962%\n",
            "Epoch 4, Loss: 0.07403043022866784, Test Loss: 0.09138082898133672, Test Accuracy: 97.02428343949045%\n",
            "Epoch 5, Loss: 0.06176981396962211, Test Loss: 0.08959078332438923, Test Accuracy: 97.20342356687898%\n",
            "Epoch 6, Loss: 0.0565467014352653, Test Loss: 0.10024597880409758, Test Accuracy: 96.96457006369427%\n",
            "Epoch 7, Loss: 0.04865642305435504, Test Loss: 0.08366975214559982, Test Accuracy: 97.46218152866243%\n",
            "Epoch 8, Loss: 0.04585914536558493, Test Loss: 0.1111543726326038, Test Accuracy: 96.89490445859873%\n",
            "Epoch 9, Loss: 0.04037120858875244, Test Loss: 0.08179352888158985, Test Accuracy: 97.75079617834395%\n",
            "Epoch 10, Loss: 0.03676919062653043, Test Loss: 0.08529485990911086, Test Accuracy: 97.7607484076433%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 분류"
      ],
      "metadata": {
        "id": "4Fa7MsJ86W6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 swish"
      ],
      "metadata": {
        "id": "CQJEj1FmvjBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diNRMpLN3X8Z",
        "outputId": "f43a6b46-07d7-417f-d3d5-0d73d5476d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6542027058753561, Test Loss: 0.5580013565560604, Test Accuracy: 78.74715045592706%\n",
            "Epoch 2, Loss: 0.5096942858493074, Test Loss: 0.48384127464700255, Test Accuracy: 80.80357142857143%\n",
            "Epoch 3, Loss: 0.43036826031005126, Test Loss: 0.4990546056564818, Test Accuracy: 79.8109802431611%\n",
            "Epoch 4, Loss: 0.37340445917971593, Test Loss: 0.5056905971562609, Test Accuracy: 81.24525075987842%\n",
            "Epoch 5, Loss: 0.3200741209882371, Test Loss: 0.4962940942099754, Test Accuracy: 82.09536474164133%\n",
            "Epoch 6, Loss: 0.2827190731117066, Test Loss: 0.5119229301493219, Test Accuracy: 81.38772796352583%\n",
            "Epoch 7, Loss: 0.23490818456766452, Test Loss: 0.5415984772621317, Test Accuracy: 82.04312310030396%\n",
            "Epoch 8, Loss: 0.20509039376010285, Test Loss: 0.6256535573208586, Test Accuracy: 81.25%\n",
            "Epoch 9, Loss: 0.18551685756191294, Test Loss: 0.6219574333505428, Test Accuracy: 81.94338905775076%\n",
            "Epoch 10, Loss: 0.1639283260607973, Test Loss: 0.684867446726941, Test Accuracy: 81.13126899696049%\n"
          ]
        }
      ],
      "source": [
        "# 신경망 정의\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)  # 클래스 수 3\n",
        "        self.swish = Swish()  # Swish 활성화 함수 인스턴스화\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)  # 평탄화\n",
        "        x = self.swish(self.fc1(x))\n",
        "        x = self.swish(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# 모델 훈련 및 평가 함수\n",
        "def train_and_evaluate(model, criterion, optimizer, train_loader, test_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                test_acc += accuracy(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_acc /= len(test_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Test Loss: {test_loss}, Test Accuracy: {test_acc}%')\n",
        "\n",
        "# 모델 훈련 및 평가\n",
        "train_and_evaluate(model, criterion, optimizer, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=4일때"
      ],
      "metadata": {
        "id": "DfY6AyQcvlvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FSSwish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FSSwish, self).__init__()\n",
        "        self.h = torch.tensor([5.9128, 2.9864, 1.4755, 0.4429], dtype=torch.float32)\n",
        "        self.d = torch.tensor([6.0788, 3.0843, 1.5167, 0.7723], dtype=torch.float32)\n",
        "        self.T = torch.tensor([5.7271, 2.8642, 1.3162, 0.6181], dtype=torch.float32)\n",
        "        self.K = len(self.h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        v = x\n",
        "\n",
        "        # Initialize temporary output for FS spike neural network\n",
        "        temp_out = torch.zeros_like(v)\n",
        "\n",
        "        # Implement FS spike neural network\n",
        "        for t in range(len(self.T)):\n",
        "            v_scaled = (v - self.T[t]) / (torch.abs(v) + 1)\n",
        "            z = spike_function(v_scaled)\n",
        "            temp_out += z * self.d[t]\n",
        "            v = v - z * self.h[t]\n",
        "\n",
        "        return temp_out"
      ],
      "metadata": {
        "id": "kAHO2szvxFYX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FSSwish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FSSwish, self).__init__()\n",
        "        self.h = torch.tensor([5.9128, 2.9864, 1.4755, 0.4429], dtype=torch.float32)\n",
        "        self.d = torch.tensor([6.0788, 3.0843, 1.5167, 0.7723], dtype=torch.float32)\n",
        "        self.T = torch.tensor([5.7271, 2.8642, 1.3162, 0.6181], dtype=torch.float32)\n",
        "        self.K = len(self.h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        v = x\n",
        "\n",
        "        # Initialize temporary output for FS spike neural network\n",
        "        temp_out = torch.zeros_like(v)\n",
        "\n",
        "        # Implement FS spike neural network\n",
        "        for t in range(len(self.T)):\n",
        "            v_scaled = (v - self.T[t]) / (torch.abs(v) + 1)\n",
        "            z = spike_function(v_scaled)\n",
        "            temp_out += z * self.d[t]\n",
        "            v = v - z * self.h[t]\n",
        "\n",
        "        return temp_out"
      ],
      "metadata": {
        "id": "n1nJoLhuyhkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 정의\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)  # 클래스 수 3\n",
        "        self.fs_swish1 = FSSwish()\n",
        "        self.fs_swish2 = FSSwish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)  # 평탄화\n",
        "        x = self.fs_swish1(self.fc1(x))\n",
        "        x = self.fs_swish2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# 모델 훈련 및 평가 함수\n",
        "def train_and_evaluate(model, criterion, optimizer, train_loader, test_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                test_acc += accuracy(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_acc /= len(test_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Test Loss: {test_loss}, Test Accuracy: {test_acc}%')\n",
        "\n",
        "# 모델 훈련 및 평가\n",
        "train_and_evaluate(model, criterion, optimizer, train_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_i3BfP3vlYc",
        "outputId": "5ac77a6c-1220-4b34-da76-db09c42ff3db"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6810605652788853, Test Loss: 0.5636912000940201, Test Accuracy: 77.65007598784194%\n",
            "Epoch 2, Loss: 0.5287138727117092, Test Loss: 0.5294463869104994, Test Accuracy: 78.14399696048632%\n",
            "Epoch 3, Loss: 0.4478860357974438, Test Loss: 0.48209420607445086, Test Accuracy: 80.90805471124621%\n",
            "Epoch 4, Loss: 0.38907484494625255, Test Loss: 0.4741644060358088, Test Accuracy: 82.1048632218845%\n",
            "Epoch 5, Loss: 0.3445899662185223, Test Loss: 0.48440222790900694, Test Accuracy: 81.33073708206686%\n",
            "Epoch 6, Loss: 0.28760026236797903, Test Loss: 0.520010549337306, Test Accuracy: 80.28115501519757%\n",
            "Epoch 7, Loss: 0.24836368678098028, Test Loss: 0.5151726020143387, Test Accuracy: 80.12917933130699%\n",
            "Epoch 8, Loss: 0.21059976343778855, Test Loss: 0.5500455796718597, Test Accuracy: 81.08377659574468%\n",
            "Epoch 9, Loss: 0.18493643533042137, Test Loss: 0.5761560956214337, Test Accuracy: 82.1523556231003%\n",
            "Epoch 10, Loss: 0.1686219625809091, Test Loss: 0.6144288137872168, Test Accuracy: 81.1502659574468%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=16일때"
      ],
      "metadata": {
        "id": "Un7e-pztwvbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FSSwish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FSSwish, self).__init__()\n",
        "        self.h = torch.tensor([-0.3462,  1.7540,  0.7608,  2.2101,  2.2010,  2.0671,  1.5055,  0.9358,\n",
        "0.7226,  0.5611,  0.4563,  0.3873,  0.3402,  0.3063,  0.2518,  0.2383], dtype=torch.float32)\n",
        "        self.d = torch.tensor([-0.1988,  1.8982,  0.5589,  2.2857,  2.2202,  2.0731,  1.5142,  0.9145,\n",
        "0.6390,  0.4360,  0.3265,  0.2403,  0.1830,  0.1436,  0.1209,  0.1377], dtype=torch.float32)\n",
        "        self.T = torch.tensor([-3.7520,  3.2999,  0.7893,  2.3260,  2.3061,  2.1326,  1.5841,  0.9676,\n",
        "0.7256,  0.5612,  0.4561,  0.3868,  0.3397,  0.3061,  0.2929,  0.2950], dtype=torch.float32)\n",
        "        self.K = len(self.h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        v = x\n",
        "\n",
        "        # Initialize temporary output for FS spike neural network\n",
        "        temp_out = torch.zeros_like(v)\n",
        "\n",
        "        # Implement FS spike neural network\n",
        "        for t in range(len(self.T)):\n",
        "            v_scaled = (v - self.T[t]) / (torch.abs(v) + 1)\n",
        "            z = spike_function(v_scaled)\n",
        "            temp_out += z * self.d[t]\n",
        "            v = v - z * self.h[t]\n",
        "\n",
        "        return temp_out"
      ],
      "metadata": {
        "id": "KXhM9V1Qwwlu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 정의\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)  # 클래스 수 3\n",
        "        self.fs_swish1 = FSSwish()\n",
        "        self.fs_swish2 = FSSwish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)  # 평탄화\n",
        "        x = self.fs_swish1(self.fc1(x))\n",
        "        x = self.fs_swish2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# 모델 훈련 및 평가 함수\n",
        "def train_and_evaluate(model, criterion, optimizer, train_loader, test_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                test_acc += accuracy(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_acc /= len(test_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Test Loss: {test_loss}, Test Accuracy: {test_acc}%')\n",
        "\n",
        "# 모델 훈련 및 평가\n",
        "train_and_evaluate(model, criterion, optimizer, train_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D7DhrjjxMwF",
        "outputId": "7f8ef55f-208b-4257-94ab-6271df5267eb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6573027565124187, Test Loss: 0.556056982025187, Test Accuracy: 76.92819148936171%\n",
            "Epoch 2, Loss: 0.5101463003361478, Test Loss: 0.5050672641459931, Test Accuracy: 79.41679331306992%\n",
            "Epoch 3, Loss: 0.43620246192242235, Test Loss: 0.533622716969632, Test Accuracy: 79.90121580547113%\n",
            "Epoch 4, Loss: 0.38436375932490574, Test Loss: 0.5088746687199207, Test Accuracy: 80.68484042553192%\n",
            "Epoch 5, Loss: 0.3197494422818752, Test Loss: 0.48962205775240636, Test Accuracy: 81.78191489361703%\n",
            "Epoch 6, Loss: 0.2754131350111454, Test Loss: 0.526522511497457, Test Accuracy: 80.54711246200608%\n",
            "Epoch 7, Loss: 0.2432443140986118, Test Loss: 0.5358133639426942, Test Accuracy: 80.1006838905775%\n",
            "Epoch 8, Loss: 0.20029366594996859, Test Loss: 0.580719438005001, Test Accuracy: 82.3233282674772%\n",
            "Epoch 9, Loss: 0.17168254760351587, Test Loss: 0.634213370845673, Test Accuracy: 81.35448328267476%\n",
            "Epoch 10, Loss: 0.15401994945838096, Test Loss: 0.6723577988908646, Test Accuracy: 81.39247720364742%\n"
          ]
        }
      ]
    }
  ]
}